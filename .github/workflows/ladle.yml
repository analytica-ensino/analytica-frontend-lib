name: Deploy Ladle to DigitalOcean Spaces

on:
  workflow_call:
    inputs:
      cache-key:
        description: 'Cache key for node_modules'
        required: true
        type: string
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: yarn

      - name: Restore node_modules cache
        uses: actions/cache/restore@v4
        with:
          path: |
            node_modules
            .yarn/cache
            .pnp.*
          key: ${{ inputs.cache-key }}
          fail-on-cache-miss: true

      - name: Build Ladle
        run: yarn ladle:build
        env:
          NODE_OPTIONS: --max-old-space-size=8192

      - name: Configure AWS CLI for DigitalOcean Spaces
        run: |
          aws configure set aws_access_key_id ${{ secrets.DO_SPACES_ACCESS_KEY }}
          aws configure set aws_secret_access_key ${{ secrets.DO_SPACES_SECRET_KEY }}
          aws configure set default.region ${{ secrets.DO_SPACES_REGION }}
          aws configure set default.output json

      - name: Check bucket status
        id: bucket_check
        run: |
          if aws s3 ls s3://${{ secrets.DO_SPACES_BUCKET }} --endpoint-url https://${{ secrets.DO_SPACES_REGION }}.digitaloceanspaces.com --max-items 1 > /dev/null 2>&1; then
            echo "bucket_has_content=true" >> $GITHUB_OUTPUT
          else
            echo "bucket_has_content=false" >> $GITHUB_OUTPUT
          fi

      - name: Deploy to DigitalOcean Spaces (Initial upload)
        if: steps.bucket_check.outputs.bucket_has_content == 'false'
        run: |
          # Upload all files maintaining structure with public read access
          aws s3 cp build/ s3://${{ secrets.DO_SPACES_BUCKET }}/ \
            --endpoint-url https://${{ secrets.DO_SPACES_REGION }}.digitaloceanspaces.com \
            --recursive \
            --acl public-read \
            --cache-control "public, max-age=86400"

          # Override cache for HTML files
          aws s3 cp build/index.html s3://${{ secrets.DO_SPACES_BUCKET }}/index.html \
            --endpoint-url https://${{ secrets.DO_SPACES_REGION }}.digitaloceanspaces.com \
            --acl public-read \
            --cache-control "no-cache, no-store, must-revalidate" \
            --content-type "text/html"

      - name: Deploy to DigitalOcean Spaces (Update)
        if: steps.bucket_check.outputs.bucket_has_content == 'true'
        run: |
          # Sync all files maintaining structure with public read access
          aws s3 sync build/ s3://${{ secrets.DO_SPACES_BUCKET }}/ \
            --endpoint-url https://${{ secrets.DO_SPACES_REGION }}.digitaloceanspaces.com \
            --delete \
            --acl public-read \
            --cache-control "public, max-age=86400"

          # Override cache for HTML files
          aws s3 cp build/index.html s3://${{ secrets.DO_SPACES_BUCKET }}/index.html \
            --endpoint-url https://${{ secrets.DO_SPACES_REGION }}.digitaloceanspaces.com \
            --acl public-read \
            --cache-control "no-cache, no-store, must-revalidate" \
            --content-type "text/html"
